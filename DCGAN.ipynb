{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DCGAN.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyORa4hNpRyDMnAVwVqxkr4W",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/spctr01/PyTorch/blob/master/DCGAN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4mpFDkG3V_5x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from __future__ import print_function\n",
        "import argparse\n",
        "import os\n",
        "import random\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.parallel\n",
        "import torch.backends.cudnn as cudnn\n",
        "import torch.optim as optim\n",
        "import torch.utils.data\n",
        "import torchvision.datasets as dset\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.utils as vutils\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.animation as animation\n",
        "from IPython.display  import HTML\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QJlYiSS5XVyJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "manualSeed = 999\n",
        "random.seed(manualSeed)\n",
        "torch.manual_seed(manualSeed)\n",
        "\n",
        "# Root directory for dataset\n",
        "dataroot = \"celeba\"\n",
        "\n",
        "# Number of workers for dataloader\n",
        "workers = 2\n",
        "\n",
        "# Batch size during training\n",
        "batch_size = 128\n",
        "\n",
        "# Spatial size of training images. All images will be resized to this\n",
        "#   size using a transformer.\n",
        "image_size = 64\n",
        "\n",
        "# Number of channels in the training images. For color images this is 3\n",
        "nc = 3\n",
        "\n",
        "# Size of z latent vector (i.e. size of generator input)\n",
        "nz = 100\n",
        "\n",
        "# Size of feature maps in generator\n",
        "ngf = 64\n",
        "\n",
        "# Size of feature maps in discriminator\n",
        "ndf = 64\n",
        "\n",
        "# Number of training epochs\n",
        "num_epochs = 5\n",
        "\n",
        "# Learning rate for optimizers\n",
        "lr = 0.0002\n",
        "\n",
        "# Beta1 hyperparam for Adam optimizers\n",
        "beta1 = 0.5\n",
        "\n",
        "# Number of GPUs available. Use 0 for CPU mode.\n",
        "ngpu = 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q0dHNgLsaiyt",
        "colab_type": "code",
        "outputId": "e13ff335-1f90-4548-ae9a-702f2fd7b53d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 132
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fncxcFJ8HL3J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ls"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x2jQCZGbcnj4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataset = dset.ImageFolder(root=dataroot,\n",
        "                           transform=transforms.Compose([\n",
        "                               transforms.Resize(image_size),\n",
        "                               transforms.CenterCrop(image_size),\n",
        "                               transforms.ToTensor(),\n",
        "                               transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
        "                           ]))\n",
        "\n",
        "dataloader = torch.utils.data.DataLoader(dataset, batch_size=batch_size,shuffle=True,num_workers=workers)\n",
        "\n",
        "device = torch.device(\"cuda:0\" if (torch.cuda.is_available() and ngpu > 0) else \"cpu\")\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hkkuHO6hJT4d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#custom weight initialization normal distribution  with meean 0 and stdev 0.02\n",
        "\n",
        "def weight_init(m):\n",
        "  classname = m.__class__.__name__\n",
        " \n",
        "  if classname.find('Conv') != -1:\n",
        "        nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
        "  elif classname.find('BatchNorm') != -1:\n",
        "        nn.init.normal_(m.weight.data, 1.0, 0.02)\n",
        "        nn.init.constant_(m.bias.data, 0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RjAZzvcPKhNH",
        "colab_type": "code",
        "outputId": "e4af19f1-6c57-479c-e9a3-b6ec7c5018bb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 379
        }
      },
      "source": [
        "#Generator\n",
        "\n",
        "class Generator(nn.Module):\n",
        "  def __init__(self,ngpu):\n",
        "    super(Generator,self).__init__()\n",
        "    self.ngpu = ngpu\n",
        "    self.main = nn.Sequential(\n",
        "        nn.ConvTranspose2d(nz, ngf*8,4,1,0, bias=False),\n",
        "        nn.BatchNorm2d(ngf*8),\n",
        "        nn.ReLU(True),\n",
        "\n",
        "        nn.ConvTranspose2d(ngf*8, ngf*4, 4,2,1, bias=False),\n",
        "        nn.BatchNorm2d(ngf*4),\n",
        "        nn.ReLU(True),\n",
        "\n",
        "        nn.ConvTranspose2d(ngf*4, ngf*2, 4,2,1, bias=False),\n",
        "        nn.BatchNorm2d(ngf*2),\n",
        "        nn.ReLU(True),\n",
        "\n",
        "        nn.ConvTranspose2d(ngf*2,ngf, 4,2,1 ,bias=False),\n",
        "        nn.BatchNorm2d(ngf*2),\n",
        "        nn.ReLU(True),\n",
        "        \n",
        "        nn.ConvTranspose2d(ngf,nc, 4,2,1, bias=False),\n",
        "        nn.Tanh()\n",
        "    )\n",
        "\n",
        "  def forward(self,input):\n",
        "    return self.main(input)\n",
        "\n",
        "\n",
        "netG = Generator(ngpu).to(device)\n",
        "\n",
        "netG.apply(weight_init)\n",
        "\n",
        "print(netG)\n",
        "    "
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Generator(\n",
            "  (main): Sequential(\n",
            "    (0): ConvTranspose2d(100, 512, kernel_size=(4, 4), stride=(1, 1), bias=False)\n",
            "    (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): ConvTranspose2d(512, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "    (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (5): ReLU(inplace=True)\n",
            "    (6): ConvTranspose2d(256, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "    (7): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (8): ReLU(inplace=True)\n",
            "    (9): ConvTranspose2d(128, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "    (10): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (11): ReLU(inplace=True)\n",
            "    (12): ConvTranspose2d(64, 3, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "    (13): Tanh()\n",
            "  )\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vvzizxnL6F9L",
        "colab_type": "code",
        "outputId": "853e4900-e644-4198-ae2a-c75d2d1f361d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        }
      },
      "source": [
        "#Discriminator\n",
        "\n",
        "class Discriminator(nn.Module):\n",
        "  def __init__(self,ngpu):\n",
        "    super(Discriminator, self).__init__()\n",
        "    self.ngpu = ngpu\n",
        "    self.main = nn.Sequential(\n",
        "        nn.Conv2d(nc,ndf, 4,2,1, bias=False),\n",
        "        nn.LeakyReLU(0.2, inplace=True),\n",
        "\n",
        "        nn.Conv2d(ndf, ndf*2, 4,2,1, bias=False),\n",
        "        nn.BatchNorm2d(ndf*2),\n",
        "        nn.LeakyReLU(0.2, inplace=False),\n",
        "\n",
        "        nn.Conv2d(ndf*2, ndf*4, 4,2,1, bias=False),\n",
        "        nn.BatchNorm2d(ndf*4),\n",
        "        nn.LeakyReLU(0.2, inplace=False),  \n",
        "\n",
        "        nn.Conv2d(ndf*4, ndf*8, 4,2,1, bias=False),\n",
        "        nn.BatchNorm2d(ndf*8),\n",
        "        nn.LeakyReLU(0.2, inplace=False),   \n",
        "\n",
        "        nn.Conv2d(ndf*8, 1, 4,2,1, bias=False),\n",
        "        nn.Sigmoid()\n",
        "        \n",
        "    )\n",
        "\n",
        "  def forward(self,input):\n",
        "    return self.main(input)\n",
        "\n",
        "netD = Discriminator(ngpu).to(device)\n",
        "netD.apply(weight_init)\n",
        "print(netD)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Discriminator(\n",
            "  (main): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "    (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
            "    (2): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "    (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (4): LeakyReLU(negative_slope=0.2)\n",
            "    (5): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "    (6): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (7): LeakyReLU(negative_slope=0.2)\n",
            "    (8): Conv2d(256, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "    (9): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (10): LeakyReLU(negative_slope=0.2)\n",
            "    (11): Conv2d(512, 1, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "    (12): Sigmoid()\n",
            "  )\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "naFuuPa39PIS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "criterion = nn.BCELoss()\n",
        "real_label = 1\n",
        "fake_label = 0\n",
        "optimizerD = optim.Adam(netD.parameters(), lr=lr, betas=(beta1, 0.999))\n",
        "optimizerG = optim.Adam(netG.parameters(), lr=lr, betas=(beta1, 0.999))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pb036XD_c9PA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for epoch in range(num_epochs):\n",
        "  \n",
        "  for i,data in enumerate(dataloader,0):\n",
        "    #training with real batches\n",
        "    netD.zero_grad()\n",
        "    real_cpu = data[0].to(device)\n",
        "    b_size = real_cpu.size(0)\n",
        "    label = torch.full((b_size,),real_label, device= device)\n",
        "\n",
        "    output = netD(real_cpu).view(-1)\n",
        "    eerD_real = criterion(output, label)\n",
        "    #calculate gradient\n",
        "    eerD_real.backward()\n",
        "    D_x = output.mean().item()\n",
        "\n",
        "\n",
        "    #training with fake batches \n",
        "    noise = torch.randn(b_size,nz,1,1, device=device)\n",
        "    #generate fake images\n",
        "    fake = netG(noice)\n",
        "    label.fill_(fake_label)\n",
        "\n",
        "    output = netD(fake.detach()).view(-1)\n",
        "    eerD_fake = critersion(output,label)\n",
        "    eerD_fake.backward()\n",
        "    D_G_z1 = output.mean().item()\n",
        "\n",
        "    eerD = eerD_real +eerD_fake\n",
        "    optimizerD.step()\n",
        "\n",
        "\n",
        "    #update generator\n",
        "    netG.zero_grad()\n",
        "    label.fill_real(real_label)\n",
        "    output = netD(fake).view(-1)\n",
        "    errG = criterion(output, label)\n",
        "    errG.backward()\n",
        "    D_G_z2 = output.mean().item() \n",
        "    optimizerG.step()\n",
        "\n",
        "\n",
        "     # Output training stats\n",
        "    if i % 50 == 0:\n",
        "            print('[%d/%d][%d/%d]\\tLoss_D: %.4f\\tLoss_G: %.4f\\tD(x): %.4f\\tD(G(z)): %.4f / %.4f'\n",
        "                  % (epoch, num_epochs, i, len(dataloader),\n",
        "                     errD.item(), errG.item(), D_x, D_G_z1, D_G_z2))\n",
        "\n",
        "    # Save Losses for plotting later\n",
        "    G_losses.append(errG.item())\n",
        "    D_losses.append(errD.item())\n",
        "    \n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rnlL94nekeib",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B9YAMzTfzxvQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "a= torch.rand(3,2, device=device)\n",
        "print(a)\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}